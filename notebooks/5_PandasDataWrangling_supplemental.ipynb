{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13zUoDymWjoj"
   },
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdYs70QQWjot",
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with structured data such as tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyPubbN1Ll3L"
   },
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS_ofld5Ll3L"
   },
   "source": [
    "The syntax of JSON is very similar to the syntax of `int`, `str`, `list` and `dict` data types in Python. \n",
    "\n",
    "The following data (excerpt) is taken from the data that feeds the Instagram page of the UvA (https://www.instagram.com/uva_amsterdam/). The API/service of Instagram returns web data in JSON that is used by your browser to show you a page with content. You can also find this when inspecting the source of the page. \n",
    "\n",
    "A JSON file (named `example.json`) that looks like this:\n",
    "```json\n",
    "{\n",
    "    \"biography\": \"Welcome to the UvA \\u274c\\u274c\\u274c \\nFind out more about our:\\n\\ud83c\\udfdb campuses \\ud83c\\udf93 education \\ud83d\\udd0e research\\nShare your \\ud83d\\udcf8 using: #uva_amsterdam\\nQuestions? Contact us:\",\n",
    "    \"blocked_by_viewer\": false,\n",
    "    \"restricted_by_viewer\": null,\n",
    "    \"country_block\": false,\n",
    "    \"external_url\": \"https://linkin.bio/uva_amsterdam\",\n",
    "    \"external_url_linkshimmed\": \"https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fuva_amsterdam\\u0026e=ATOBo7L11uPBpsMfd6-pFnoBRaF3T-6ovlD9Blc2q1LGUjnmyuGutPfuK-ib70Bt_YmGu6cDNCX1Y1lC\\u0026s=1\",\n",
    "    \"edge_followed_by\": {\n",
    "        \"count\": 42241\n",
    "    },\n",
    "    \"fbid\": \"17841401222133463\",\n",
    "    \"followed_by_viewer\": false,\n",
    "    \"edge_follow\": {\n",
    "        \"count\": 362\n",
    "    },\n",
    "    \"follows_viewer\": false,\n",
    "    \"full_name\": \"UvA: University of Amsterdam\",\n",
    "    \"id\": \"1501672737\",\n",
    "    \"is_business_account\": true,\n",
    "    \"is_joined_recently\": false,\n",
    "    \"business_category_name\": \"Professional Services\",\n",
    "    \"overall_category_name\": null,\n",
    "    \"category_enum\": \"UNIVERSITY\",\n",
    "    \"category_name\": null,\n",
    "    \"profile_pic_url\": \"https://scontent-amt2-1.cdninstagram.com/v/t51.2885-19/s150x150/117066908_1128864954173821_2797787766361156925_n.jpg?_nc_ht=scontent-amt2-1.cdninstagram.com\\u0026_nc_ohc=PXsEzg-CKaUAX8dEtNL\\u0026tp=1\\u0026oh=86bb46d8006b77db2037955187e69de1\\u0026oe=6056619F\",\n",
    "    \"username\": \"uva_amsterdam\",\n",
    "    \"connected_fb_page\": null\n",
    "}\n",
    "```\n",
    "\n",
    "Can be loaded into Python as a dictionary:\n",
    "```python\n",
    "{\n",
    "    'biography': 'Welcome to the UvA ‚ùå‚ùå‚ùå \\nFind out more about our:\\nüèõ campuses üéì education üîé research\\nShare your üì∏ using: #uva_amsterdam\\nQuestions? Contact us:',\n",
    "     'blocked_by_viewer': False,\n",
    "     'restricted_by_viewer': None,\n",
    "     'country_block': False,\n",
    "     'external_url': 'https://linkin.bio/uva_amsterdam',\n",
    "     'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fuva_amsterdam&e=ATOBo7L11uPBpsMfd6-pFnoBRaF3T-6ovlD9Blc2q1LGUjnmyuGutPfuK-ib70Bt_YmGu6cDNCX1Y1lC&s=1',\n",
    "     'edge_followed_by': {'count': 42241},\n",
    "     'fbid': '17841401222133463',\n",
    "     'followed_by_viewer': False,\n",
    "     'edge_follow': {'count': 362},\n",
    "     'follows_viewer': False,\n",
    "     'full_name': 'UvA: University of Amsterdam',\n",
    "     'id': '1501672737',\n",
    "     'is_business_account': True,\n",
    "     'is_joined_recently': False,\n",
    "     'business_category_name': 'Professional Services',\n",
    "     'overall_category_name': None,\n",
    "     'category_enum': 'UNIVERSITY',\n",
    "     'category_name': None,\n",
    "     'profile_pic_url': 'https://scontent-amt2-1.cdninstagram.com/v/t51.2885-19/s150x150/117066908_1128864954173821_2797787766361156925_n.jpg?_nc_ht=scontent-amt2-1.cdninstagram.com&_nc_ohc=PXsEzg-CKaUAX8dEtNL&tp=1&oh=86bb46d8006b77db2037955187e69de1&oe=6056619F',\n",
    "     'username': 'uva_amsterdam',\n",
    "     'connected_fb_page': None\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHGPI7goLl3M"
   },
   "source": [
    "The main differences between dictionaries in Python and the JSON file notation are:\n",
    "\n",
    "* Python dictionaries exist in memory in Python, they are an abstract datatype. JSON is a data format and can be saved on your computer, or be transmitted as string (e.g. for a website request, sending data).\n",
    "* Keys in JSON can only be of type string. This means that writing a Python dictionary with integers as keys will transform them to string. Reading back the file will therefore give you a Python dictionary with strings as keys.\n",
    "* All non-ascii characters are escape sequences (e.g. `\\u274c`) for ‚ùå. This is the same for letters with diacritics (e.g. √©, √™, √ß, √±). If all characters are escaped this way, you don't have to specify an encoding when opening json files.\n",
    "* `True` and `False` are lowercased: `true` and `false`. `None` is `null`. \n",
    "* JSON only allows double quotes for its \"strings\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNpfINLTLl3M"
   },
   "source": [
    "The built-in json module of Python needs to be imported first, to work with json files and notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "514uONFVLl3M"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MED6fiuLl3N"
   },
   "source": [
    "Let's read a json file from our disk using `json.load()`. The file comes from the public API of the municipality of Amsterdam to look up information on houses by searching on street name and house number. See: https://api.data.amsterdam.nl/atlas/search/adres/. Most often, information from such API's or 'REST-services' is given back in JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfgw5YwdLl3N"
   },
   "outputs": [],
   "source": [
    "with open('data/bg1.json') as jsonfile:\n",
    "    data = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WFlQfXlLl3O"
   },
   "source": [
    "Then, we can inspect the loaded data as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuoEzLhgLl3O"
   },
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accN_jr3Ll3O"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6m41aWvLl3O"
   },
   "source": [
    "When we are only interested in the information on the building, we can take out that part to store it separately. This is the first dictionary element in the list that can be found under key `data['results']`. The rest of the information is feedback from the API, telling us that there is 1 hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXL6I0n4Ll3P"
   },
   "outputs": [],
   "source": [
    "data_selection = data['results'][0]\n",
    "\n",
    "# Delete all keys starting with an _underscore\n",
    "\n",
    "for k in list(data_selection):\n",
    "    if k.startswith('_'):\n",
    "        del data_selection[k]\n",
    "\n",
    "data_selection\n",
    "# print(type(data_selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGaufHPYLl3P"
   },
   "source": [
    "Then, save it back to a json file using `json.dump()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kW0AFcj7Ll3P"
   },
   "outputs": [],
   "source": [
    "with open('stuff/bg1-selection.json', 'w') as outfile:\n",
    "    json.dump(data_selection, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73tTKTIOLl3Q"
   },
   "source": [
    "### Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBWaUEBJLl3Q"
   },
   "source": [
    "* Modify that function you previously built in the last notebook to generate statistics for a file once more so that it returns a python dictionary with these statistics.\n",
    "* Write a function that uses the `os.walk()` or `os.listdir()` method to run the file statistics function over every file in a folder. Create a dictionary that takes the file name as key, and the returned statistics dictionary as value.\n",
    "* Also add arguments for a `target_file_path`, and a `data` dictionary to that function. Use the `json.dump()` method to write the dictionary to the provided file path using a with statement.\n",
    "* Inspect the file by opening it on your computer with a text editor of some sorts. Find a way to make it 'pretty printed' (e.g. with _indents_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfKOQi_wLl3Q"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "source_folder = \"data/gutenberg-extension\"\n",
    "target_file_path = \"stuff/gutenberg-statistics.json\"\n",
    "\n",
    "def your_modified_statistics_function(file_path):\n",
    "    # Your code\n",
    "    \n",
    "    return statistics_dict\n",
    "\n",
    "def your_functions_here():\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gWLRatDWjot"
   },
   "source": [
    "# Data wrangling with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DIIgvmlWjot"
   },
   "source": [
    "## CSV (in Pandas)\n",
    "\n",
    "The other often used file type is CSV (Comma Separated Values), or variants, such as TSV (Tab Separated Values). Python includes another built-in module to deal with these files: the `csv` module. But, we will be using the `Pandas` module, the go-to package for data analysis, that you already imported and updated in Notebook 0. \n",
    "\n",
    "A CSV file is similar to an Excel or Google Docs spreadsheet, but more limited in markup and functionality (e.g. you cannot store Excel functions). It is just a text file in which individual entries correspond to lines, and columns are separated by a comma. You can always open a CSV file with a text editor, and this also makes it so easy to store and share data with.\n",
    "\n",
    "For the rest of the notebook we will see how to work with the two main data types in `pandas`: the `DataFrame` and a `Series`.\n",
    "\n",
    "Information on functions and modules of Pandas cannot be found in the Python manual online, as it is an external package. Instead, you can refer to https://pandas.pydata.org/pandas-docs/stable/index.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT-DeTVZWjo0"
   },
   "source": [
    "### Looping over DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgq83jp3fE1W"
   },
   "source": [
    "Here is the third way to loop over dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zd_rZaWbekwm"
   },
   "outputs": [],
   "source": [
    "for r in df:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGKJuYDTWjo0"
   },
   "source": [
    "#### `zip(df['column1', df['column2')`\n",
    "Going over these items in a `for` loop needs a different approach. The built-in `zip()` function ([manual](https://docs.python.org/3/library/functions.html#zip)) takes two iterables of even length and creates a new iterable of tuples. The number of arguments/iterables that you give to `zip()` determines the length of the tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NdOQEuXWjo0"
   },
   "outputs": [],
   "source": [
    "list1 = ['a', 'b', 'c']\n",
    "list2 = [1, 2, 3]\n",
    "\n",
    "list(zip(list1, list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA3u6-_oWjo0"
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "for movie, imdb in zip(df['movie'], df['imdb']):\n",
    "    \n",
    "    if n > 9:\n",
    "        break  # stop flooding the Notebook\n",
    "    \n",
    "    print(movie, \"http://www.imdb.com/title/\" + imdb, sep='\\t')\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoyJmpb3Wjo-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOUj79AmWjo-"
   },
   "source": [
    "# Data wrangling (example)\n",
    "\n",
    "We can take a look at another example. We consider a dataset of tweets from Elon Musk, SpaceX and Tesla founder, and ask the following questions:\n",
    "* When is Elon most actively tweeting?\n",
    "\n",
    "While this question is a bit trivial, it will allow us to learn how to wrangle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnR8cCCuWjo-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anjFRsrJWjo-"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEkE4d1OWjo_"
   },
   "source": [
    "Let's read in a CSV file containing an export of [Elon Musk's tweets](https://twitter.com/elonmusk), exported from Twitter's API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRnIjOf3Wjo_"
   },
   "outputs": [],
   "source": [
    "dataset_path = 'data/elonmusk_tweets.csv'\n",
    "df = pd.read_csv(dataset_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFVsux4FWjo_"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqXEcft-WjpA"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phSczVrXWjpA"
   },
   "source": [
    "Let's give this dataset a bit more structure:\n",
    "- The `id` column can be transformed into the dataframe's index, thus enabling us e.g. to select a tweet by id;\n",
    "- The column `created_at` contains a timestamp, thus it can easily be converted into a `datetime` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQgtlrIVWjpA"
   },
   "outputs": [],
   "source": [
    "df.set_index('id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItrFglkNWjpB"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUmUplYpWjpB"
   },
   "outputs": [],
   "source": [
    "df.created_at = pd.to_datetime(df.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjlGsSCKWjpB"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DATHvnUWjpB"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95sY7ZPfWjpB"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmw2eKvzWjpB"
   },
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UfnizmJWjpC"
   },
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZBwFCwuWjpC"
   },
   "source": [
    "An operation on dataframes that you'll find yourself doing very often is to rename the columns. The first way of renaming columns is by manipulating directly the dataframe's index via the `columns` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNyjLCyWWjpC"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "difr2WuLWjpC"
   },
   "source": [
    "We can change the column names by assigning to `columns` a list having as values the new column names.\n",
    "\n",
    "**NB**: the size of the list and new number of colums must match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9rk9GMAWjpC"
   },
   "outputs": [],
   "source": [
    "# here we renamed the column `text` => `tweet`\n",
    "df.columns = ['created_at', 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0N8Tp9lVWjpC"
   },
   "outputs": [],
   "source": [
    "# let's check that the change did take place\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvo42ui6WjpC"
   },
   "source": [
    "The second way of renaming colums is to use the method `rename()` of a dataframe. The `columns` parameter takes a dictionary of mappings between old and new column names.\n",
    "\n",
    "```python\n",
    "mapping_dict = {\n",
    "    \"old_column_name\": \"new_column_name\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWwroMmuWjpD"
   },
   "outputs": [],
   "source": [
    "# let's change column `tweet` => `text`\n",
    "df = df.rename(columns={\"tweet\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9du3B6LWjpD"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX1Clp-LWjpD"
   },
   "source": [
    "**Question**: in which cases is it more convenient to use the second method over the first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSyzgI-KWjpD"
   },
   "source": [
    "#### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgADy6B_WjpD"
   },
   "outputs": [],
   "source": [
    "# this selects one single column and returns as a Series\n",
    "df[\"created_at\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ts8-demWjpD"
   },
   "outputs": [],
   "source": [
    "type(df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HA8veWZYWjpD"
   },
   "outputs": [],
   "source": [
    "# whereas this syntax selects one single column\n",
    "# but returns a Dataframe\n",
    "df[[\"created_at\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPanFWGVWjpE"
   },
   "outputs": [],
   "source": [
    "type(df[[\"created_at\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JVkvqrMWjpF"
   },
   "source": [
    "####  Selecting rows\n",
    "\n",
    "Filtering rows in `pandas` is done by means of `[ ]`, which can contain the row number as well as a condition for the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHmk-0MNWjpF"
   },
   "outputs": [],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5WF65O6WjpF"
   },
   "source": [
    "### Transformation\n",
    "\n",
    "\n",
    "The two main functions used to manipulate and transform values in a dataframe are:\n",
    "- `.map()` (on Series only!)\n",
    "- `.apply()`\n",
    "\n",
    "In this section we'll be using both to enrich our datasets with useful information (useful for exploration, for later visualizations, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0vPCd_IWjpF"
   },
   "source": [
    "#### Add link to original tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOeYNz3uWjpF"
   },
   "source": [
    "The `map()` method can be called on a column, as well as on the dataframe's index.\n",
    "\n",
    "When passed as a parameter to `map`, an 'anonymous' lambda function `lambda` can be used to transform any value from that column into another one.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUNAxlZ3WjpF"
   },
   "outputs": [],
   "source": [
    "df['tweet_link'] = df.index.map(lambda x: f'https://twitter.com/i/web/status/{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMWT4GB3WjpF"
   },
   "source": [
    "Or, maybe it is easier with a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFZtLGXPWjpF"
   },
   "outputs": [],
   "source": [
    "df['tweet_link'] = [f'https://twitter.com/i/web/status/{x}' for x in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzr3BfiZWjpG"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DGRRkkGWjpG"
   },
   "source": [
    "#### Add colums with mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cn4Hwl_dWjpG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_mentions(tweet_text):\n",
    "    \"\"\"\n",
    "    Find all @ mentions in a tweet and \n",
    "    return them as a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    regex = r'@[a-zA-Z0-9_]{1,15}'\n",
    "    mentions = re.findall(regex, tweet_text)\n",
    "    \n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7zFdmncWjpG"
   },
   "outputs": [],
   "source": [
    "df['tweet_mentions'] = df.text.apply(find_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6S0dTdeCWjpG"
   },
   "outputs": [],
   "source": [
    "df['n_mentions'] = df.tweet_mentions.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1n8B7SbfWjpG"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxVP2smVWjpG"
   },
   "source": [
    "#### Add column with week day and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkzyAnI7WjpH"
   },
   "outputs": [],
   "source": [
    "def day_of_week(t):\n",
    "    \"\"\"\n",
    "    Get the week day name from a week day integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    if t == 0:\n",
    "        return \"Monday\"\n",
    "    elif t == 1:\n",
    "        return \"Tuesday\"\n",
    "    elif t == 2:\n",
    "        return \"Wednesday\"\n",
    "    elif t == 3:\n",
    "        return \"Thursday\"\n",
    "    elif t == 4:\n",
    "        return \"Friday\"\n",
    "    elif t == 5:\n",
    "        return \"Saturday\"\n",
    "    elif t == 6:\n",
    "        return \"Sunday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWoQi-cTWjpH"
   },
   "outputs": [],
   "source": [
    "df[\"week_day\"] = df.created_at.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuaqzrMMWjpH"
   },
   "outputs": [],
   "source": [
    "df[\"week_day_name\"] = df[\"week_day\"].apply(day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69U8rYV9WjpH"
   },
   "source": [
    "Or, there is a built-in function in Pandas that gives back the day name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atR-yXkJWjpH"
   },
   "outputs": [],
   "source": [
    "df[\"week_day_name\"] = df.created_at.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEpNKfF_WjpH"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNyL9_17WjpH"
   },
   "source": [
    "#### Add column with day hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-5fndLAWjpI"
   },
   "outputs": [],
   "source": [
    "df.created_at.dt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "du8-hTt5WjpI"
   },
   "outputs": [],
   "source": [
    "df.created_at.dt.hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEa9CxUZWjpI"
   },
   "outputs": [],
   "source": [
    "df[\"day_hour\"] = df.created_at.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d43pcy7WjpI"
   },
   "outputs": [],
   "source": [
    "display_cols = ['created_at', 'week_day', 'day_hour']\n",
    "df[display_cols].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkyG8sbsWjpI"
   },
   "source": [
    "##### Multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVNBk98-WjpJ"
   },
   "outputs": [],
   "source": [
    "# AND condition with `&`\n",
    "\n",
    "df[\n",
    "    (df.week_day_name == 'Saturday') & (df.n_mentions == 0)\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0zJi5oEWjpJ"
   },
   "outputs": [],
   "source": [
    "# Equivalent expression with `query()`\n",
    "\n",
    "df.query(\"week_day_name == 'Saturday' and n_mentions == 0\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTO1hlNhWjpJ"
   },
   "outputs": [],
   "source": [
    "# OR condition with `|`\n",
    "\n",
    "df[\n",
    "    (df.week_day_name == 'Saturday') | (df.n_mentions == 0)\n",
    "].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGqH23K5WjpJ"
   },
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JoiqWqnWjpJ"
   },
   "outputs": [],
   "source": [
    "df.agg({'n_mentions': ['min', 'max', 'sum']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "247FXVzhWjpJ"
   },
   "source": [
    "#### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf8jfF1mWjpJ"
   },
   "outputs": [],
   "source": [
    "group_by_day = df.groupby('week_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVDAv-D5WjpK"
   },
   "outputs": [],
   "source": [
    "# The head of a DataFrameGroupBy consists of the first\n",
    "# n records for each group (see `help(grp_by_day.head)`)\n",
    "\n",
    "group_by_day.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWNCOjXtWjpK"
   },
   "source": [
    "`agg` is used to pass an aggregation function to be applied to each group resulting from `groupby`.\n",
    "\n",
    "Here we are interested in how many tweets there are for each group, so we pass `len()` to an 'aggregate'. This is similar to the `.count()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1ATt8AiWjpK"
   },
   "outputs": [],
   "source": [
    "group_by_day.agg(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOiN3zPuWjpK"
   },
   "source": [
    "However, we are not interested in having the count for all columns. Rather we want to create a new dataframe with renamed column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3avzNHOWjpK"
   },
   "outputs": [],
   "source": [
    "group_by_day.agg({'text': len}).rename({'text': 'tweet_count'}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGArxHedWjpK"
   },
   "source": [
    "##### By label (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHa_A2Q2WjpK"
   },
   "source": [
    "Previously we've added a column indicating on which day of the week a given tweet appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jZ__JQSWjpL"
   },
   "outputs": [],
   "source": [
    "groupby_result_as_series = df.groupby('day_hour')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHogxsKsWjpL"
   },
   "outputs": [],
   "source": [
    "groupby_result_as_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PurAA8tWWjpL"
   },
   "outputs": [],
   "source": [
    "groupby_result_as_df = df.groupby('day_hour')[['text']]\\\n",
    "    .count()\\\n",
    "    .rename({'text': 'count'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHmsRRGrWjpL"
   },
   "outputs": [],
   "source": [
    "groupby_result_as_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUiyZfLJWjpL"
   },
   "source": [
    "##### By series or dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl9sj2AHWjpL"
   },
   "outputs": [],
   "source": [
    "df.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qh4CJlxWjpL"
   },
   "outputs": [],
   "source": [
    "# here we pass the groups as a series\n",
    "df.groupby(df.created_at.dt.day).agg({'text':len}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_A4snuKTWjpM"
   },
   "outputs": [],
   "source": [
    "# here we pass the groups as a series\n",
    "df.groupby(df.created_at.dt.day)[['text']].count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0znvZrHWjpM"
   },
   "outputs": [],
   "source": [
    "df.groupby(df.created_at.dt.hour)[['text']].count().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAeD5HadWjpM"
   },
   "source": [
    "##### By multiple labels (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fT3UrwA3WjpM"
   },
   "outputs": [],
   "source": [
    "# Here we group based on the values of two columns\n",
    "# instead of one\n",
    "\n",
    "x = df.groupby(['week_day', 'day_hour'])[['text']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpHvHWgWWjpM"
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5zgvSBMWjpN"
   },
   "source": [
    "#### Aggregation methods\n",
    "\n",
    "**Summary**:\n",
    "\n",
    "- `count`: Number of non-NA values\n",
    "- `sum`: Sum of non-NA values\n",
    "- `mean`: Mean of non-NA values\n",
    "- `median`: Arithmetic median of non-NA values\n",
    "- `std`, `var`: standard deviation and variance\n",
    "- `min`, `max`: Minimum and maximum of non-NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McaM09oBWjpN"
   },
   "source": [
    "You can also use these in an aggregation functions within a groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av4JTDaGWjpN"
   },
   "outputs": [],
   "source": [
    "df.groupby('week_day').agg(\n",
    "    {\n",
    "        # each key in this dict specifies\n",
    "        # a given column\n",
    "        'n_mentions':[\n",
    "            # the list contains aggregation functions\n",
    "            # to be applied to this column\n",
    "            'count',\n",
    "            'mean',\n",
    "            'min',\n",
    "            'max',\n",
    "            'std',\n",
    "            'var'\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S03JNmiMWjpN"
   },
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DS3Y1I_WjpN"
   },
   "source": [
    "To sort the values of  a dataframe we use its `sort_values` method:\n",
    "- `by`: specifies the name of the column to be used for sorting\n",
    "- `ascending` (default = `True`): specifies whether the sorting should be *ascending* (A-Z, 0-9) or `descending` (Z-A, 9-0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2xx3qjhWjpN"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='created_at', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kv9H2D6bWjpO"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='n_mentions', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF2g6hKRWjpO"
   },
   "source": [
    "### Save\n",
    "\n",
    "Before continuing with the plotting, let's save our enhanced dataframe, so that we can come back to it without having to redo the same manipulations on it.\n",
    "\n",
    "`pandas` provides a number of handy functions to export dataframes in a variety of formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAXx_eFQWjpO"
   },
   "source": [
    "Here we use `.to_pickle()` to serialize the dataframe into a binary format, by using behind the scenes Python's `pickle` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJcFasz0WjpO"
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"stuff/musk_tweets_enhanced.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP15yKiGWjpO"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InFDIq1aWjpO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"stuff/musk_tweets_enhanced.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NV235sBWjpO"
   },
   "source": [
    "### `describe()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8GCeXlrWjpO"
   },
   "source": [
    "The default behavior is to include only column with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "do_rgIRFWjpP"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imeVXNXEWjpP"
   },
   "source": [
    "A trick to include more values is to exclude the datatype on which it breaks, which in our case is `list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWJ-qEuuWjpP"
   },
   "outputs": [],
   "source": [
    "df.describe(exclude=[list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVmtrWgAWjpP"
   },
   "outputs": [],
   "source": [
    "df.created_at.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kf56VOrmWjpP"
   },
   "outputs": [],
   "source": [
    "df['week_day_name'] = df['week_day_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9C-ZeKYWjpP"
   },
   "outputs": [],
   "source": [
    "df.describe(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtuFoYDKWjpP"
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ept3KEdqWjpP"
   },
   "outputs": [],
   "source": [
    "# Not needed in newest Pandas version\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6a3V4JnWjpQ"
   },
   "source": [
    "#### Histograms\n",
    "\n",
    "They are useful to see the distribution of a certain variable in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSIvsnS2WjpQ"
   },
   "outputs": [],
   "source": [
    "df.groupby(['n_mentions'])[['text']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jf8tZ8zeWjpQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df.n_mentions, bins='auto', rwidth=1.0)\n",
    "plt.title('Distribution of the number of mentions per tweet')\n",
    "plt.ylabel(\"Tweets\")\n",
    "plt.xlabel(\"Mentions (per tweet)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mw3FT2I1WjpQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df.day_hour, bins='auto', rwidth=0.6)\n",
    "plt.title('Distribution of the number of mentions per tweet')\n",
    "plt.ylabel(\"Tweets\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nhigOF3WjpQ"
   },
   "outputs": [],
   "source": [
    "df_2017 = df[df.created_at.dt.year == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL5IrIngWjpQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_2017.day_hour, bins='auto', rwidth=0.6)\n",
    "plt.title('Year 2017')\n",
    "plt.ylabel(\"Tweets\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY2JtrzhWjpQ"
   },
   "source": [
    "So far we have used directly `matplotlib` to generate our plots.\n",
    "\n",
    "`pandas`'s dataframes provide some methods that directly call `matplotlib`'s API behind the scenes:\n",
    "- `hist()` for histograms\n",
    "- `boxplot()` for boxplots\n",
    "- `plot()` for other types of plots (specified with e.g. `any='scatter'`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_ctcaYrWjpQ"
   },
   "source": [
    "By passing the `by` parameter to e.g. `hist()` it is possible to produce one histogram plot of a given variable for each value in another column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h35FvUBrWjpR"
   },
   "source": [
    "Let's see how we can plot the number of mentions by year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwDZHZOyWjpR"
   },
   "outputs": [],
   "source": [
    "df['year'] = df.created_at.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qabk8SHKWjpR"
   },
   "outputs": [],
   "source": [
    "axes = df.hist(column='day_hour', by='year', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxZG0diqWjpR"
   },
   "source": [
    "#### Bar charts\n",
    "\n",
    "They are useful to plot categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nazqFakwWjpR"
   },
   "outputs": [],
   "source": [
    "plt.bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nROj0KQGWjpR"
   },
   "outputs": [],
   "source": [
    "tweets_by_weekday = df.groupby(df.created_at.dt.weekday)[['text']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHrTiv6GWjpR"
   },
   "outputs": [],
   "source": [
    "week_days = [\n",
    "    \"Mon\",\n",
    "    \"Tue\",\n",
    "    \"Wed\",\n",
    "    \"Thur\",\n",
    "    \"Fri\",\n",
    "    \"Sat\",\n",
    "    \"Sun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u16bx22pWjpS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# specify the type of plot and the labels\n",
    "# for the y axis (the bars)\n",
    "plt.bar(\n",
    "    tweets_by_weekday.index,\n",
    "    tweets_by_weekday.text,\n",
    "    tick_label=week_days,\n",
    "    width=0.5\n",
    ")\n",
    "\n",
    "# give a title to the plot\n",
    "plt.title('Elon Musk\\'s week on Twitter')\n",
    "\n",
    "# give a label to the axes\n",
    "plt.ylabel(\"Number of tweets\")\n",
    "plt.xlabel(\"Week day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or-3iZHkWjpS"
   },
   "source": [
    "#### Box plots\n",
    "\n",
    "![box plot explained](https://github.com/bloemj/2022-coding-the-humanities/blob/master/notebooks/images/eda-boxplot.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8diAjB28WjpS"
   },
   "source": [
    "### Outliers, missing values\n",
    "\n",
    "An *outlier* is an observation far from the center of mass of the distribution. It might be an error or a genuine observation: this distinction requires domain knowledge. Outliers infuence the outcomes of several statistics and machine learning methods: it is important to decide how to deal with them.\n",
    "\n",
    "A *missing value* is an observation without a value. There can be many reasons for a missing value: the value might not exist (hence its absence is informative and it should be left empty) or might not be known (hence the value is existing but missing in the dataset and it should be marked as NA).\n",
    "\n",
    "*One way to think about the difference is with this Zen-like koan: An explicit missing value is the presence of an absence; an implicit missing value is the absence of a presence.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqQ9M64yWjpS"
   },
   "outputs": [],
   "source": [
    "tweets_by_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxF7BC66WjpS"
   },
   "outputs": [],
   "source": [
    "tweets_by_weekday.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMk9HWgKWjpS"
   },
   "outputs": [],
   "source": [
    "tweets_by_weekday.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQynlW_qWjpS"
   },
   "outputs": [],
   "source": [
    "plt.bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWog_GvdWjpS"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi9qNbwYWjpS"
   },
   "outputs": [],
   "source": [
    "df[['day_hour']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Abyiaf0RWjpS"
   },
   "outputs": [],
   "source": [
    "df[['day_hour']].quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWT70MgBWjpT"
   },
   "outputs": [],
   "source": [
    "df.boxplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4DqfJyuWjpT"
   },
   "outputs": [],
   "source": [
    "df[['day_hour', 'week_day_name']].boxplot(\n",
    "    by='week_day_name',\n",
    "    grid=False,\n",
    "    figsize=(8,6),\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# give a title to the plot\n",
    "plt.title('')\n",
    "\n",
    "# give a label to the axes\n",
    "plt.xlabel(\"Day of the week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OljB9txHWjpT"
   },
   "outputs": [],
   "source": [
    "df[['day_hour', 'week_day']].boxplot(\n",
    "    by='week_day',\n",
    "    grid=True, # just to show the difference with/without\n",
    "    figsize=(8,6),\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# give a title to the plot\n",
    "plt.title('')\n",
    "\n",
    "# give a label to the axes\n",
    "plt.xlabel(\"Day of the week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sybT6sNaWjpT"
   },
   "source": [
    "### Exercise 1.\n",
    "\n",
    "* Create a function that calculates the frequency of hashtags in tweets.\n",
    "* Test it on toy examples, to make sure it works.\n",
    "* Apply it to Elon Musk's tweets.\n",
    "* List the top 10 hashtags in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkfqkxeSWjpT"
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOOk4v2xWjpT"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_PandasDataWrangling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
